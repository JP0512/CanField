{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"InitialCode.ipynb","provenance":[{"file_id":"1St5GpIpChdzFUcaaScYkm5xItOXUAiUZ","timestamp":1654942078862}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["#Unet\n","\n","The following cells create a class called Unet, responsible for holding the CNN model, which will be used to classify the images."],"metadata":{"id":"Z9kro_BAKUl0"}},{"cell_type":"code","source":["# Import necessary libraries\n","from keras.models import Model\n","from keras.layers import (Input, concatenate, Conv2D, MaxPooling2D, \n","    Conv2DTranspose, Dropout, BatchNormalization, UpSampling2D, Lambda)\n","import tensorflow as tf"],"metadata":{"id":"kvenUz88KZ4T"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zi_WinfMmwKY"},"outputs":[],"source":["# Creates class\n","class Unet:\n","    def __init__(self, outchns=1):\n","        self.outchns = outchns\n","        self.model = self.build()\n","        \n","    def loadWeights(self, pathToWeights):\n","        try:\n","            self.model.load_weights(pathToWeights)\n","        except:\n","            print(pathToWeights, 'cannot be loaded')\n","\n","    def convolutionLayer(self, num_of_filters, image):\n","        conv = Conv2D(num_of_filters, (3, 3), activation='relu', padding='same')(image)\n","        conv = BatchNormalization()(conv)\n","        conv = Conv2D(num_of_filters, (3, 3), activation='relu', padding='same')(conv)\n","        conv = BatchNormalization()(conv)\n","        return conv\n","        \n","    def build(self):\n","        # Defines the input that the model will take\n","        # This is ususally the dimensions of the image\n","        inputs = Input((160, 160, 3))\n","\n","        # Sets a list of convolutions and pooling.\n","        # Check the following article for a better understanding\n","        # https://towardsdatascience.com/understanding-convolutions-and-pooling-in-neural-networks-a-simple-explanation-885a2d78f211\n","        # DRY codes\n","        layers = {}\n","        pool = inputs\n","\n","        for i in range(5, 9):\n","          conv = Unet.convolutionLayer(self, 2**i, pool)\n","          pool = MaxPooling2D(pool_size=(2, 2))(conv)\n","          layers[f'conv{i}'] = conv\n","\n","        conv = Unet.convolutionLayer(self, 2**9, pool)\n","        conv = Dropout(0.2)(conv)\n","        layers['conv9'] = conv\n","\n","        for i in range(8, 4, -1):\n","          up = concatenate([Conv2DTranspose(2**i, (3, 3), strides=(2, 2), padding='same')(layers[f'conv{i+1}']), layers[f'conv{i}']], axis=3)\n","          conv = Unet.convolutionLayer(self, 2**i, up)\n","          layers[f'conv{i+1}'] = conv\n","        \n","        conv = Conv2D(self.outchns, (1, 1), activation='sigmoid')(layers['conv6'])\n","        model = Model(inputs=[inputs], outputs=[conv])\n","\n","        return model"]},{"cell_type":"markdown","source":["#Config file\n","\n","This part of the code set the parameters to be used in other pieces of the code. The parameters are: Batch size, image resolution, number of epochs, data augmentation parameters for training and validation set."],"metadata":{"id":"xmtzMiUGK1pC"}},{"cell_type":"code","source":["import albumentations as A\n","\n","class config:\n","  BATCH_SIZE = 30\n","  IMG_SIZE = 160\n","\n","  CLASSES = 1  # number of output channels\n","\n","  EPOCHS = 50\n","\n","  # The following is used to augment the images of the dataset\n","  AUGMENTER_TRAIN = A.Compose(\n","      transforms=[\n","          A.Resize(height=IMG_SIZE, width=IMG_SIZE, always_apply=True, p=1.0),\n","          # A.RandomCrop(height=IMG_SIZE, width=IMG_SIZE, always_apply=True, p=1.0),\n","          A.Transpose(p=0.5),\n","          A.VerticalFlip(p=0.5),\n","          A.HorizontalFlip(p=0.5),\n","      ],\n","  )\n","\n","  AUGMENTER_VAL = A.Compose(\n","      transforms=[\n","          A.Resize(height=IMG_SIZE, width=IMG_SIZE, always_apply=True, p=1.0),\n","          # A.CenterCrop(height=IMG_SIZE, width=IMG_SIZE, always_apply=True, p=1.0),\n","      ],\n","  )"],"metadata":{"id":"fozzmo99K3_n"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Dataset\n","\n","Here, we are creating function that will split the data between training and testing sets, as well as implementing the data augmentation to our dataset."],"metadata":{"id":"WtmQp2eONHzn"}},{"cell_type":"code","source":["import numpy as np\n","from tensorflow.keras.preprocessing.image import Iterator\n","\n","\n","def random_image_and_mask(config):\n","    S = config.IMG_SIZE\n","    img = np.zeros(shape=(S, S, 3), dtype=np.uint8)\n","    mask = np.zeros(shape=(S, S, config.CLASSES), dtype=np.uint8)\n","\n","    # Random color for img\n","    img += np.random.randint(0, 255, size=(3,), dtype=np.uint8)\n","\n","    # Add a random box\n","    w, h = np.random.randint(int(S * 0.1), int(S * 0.3), size=(2,))\n","    box_color = np.random.randint(0, 255, size=(3,), dtype=np.uint8)\n","    x, y = np.random.randint(0, int(S * 0.9), size=(2,))\n","    img[y:y+h, x:x+w, :] = box_color\n","    mask[y:y+h, x:x+w, :] = 255\n","\n","    return img, mask\n","\n","\n","class IteratorWithAug(Iterator):\n","    \"\"\" Iterator that generate data from directory and a list of images and a\n","        corresponding list of class labels\n","    \"\"\"\n","\n","    def __init__(self,\n","                 image_paths,\n","                 mask_paths,\n","                 config,\n","                 augmenter=None,\n","                 mode=None,\n","                 shuffle=True,\n","                 batch_size=16,\n","                 seed=None,\n","                 ):\n","        self.image_paths = image_paths\n","        self.mask_paths = mask_paths\n","        self.n = len(image_paths)\n","        #assert self.n == len(mask_paths)\n","        self.batch_size = batch_size\n","        self.mode = mode\n","        self.config = config\n","        self.augmenter = augmenter\n","\n","        super().__init__(self.n,\n","                         batch_size,\n","                         shuffle,\n","                         seed=seed)\n","\n","    def _get_batches_of_transformed_samples(self, index_array):\n","        # build batch of image & gt\n","        batch_x = []\n","        batch_y = []\n","        for i, j in enumerate(index_array):\n","            # TODO: read rgb from: self.image_paths[j]\n","            # TODO: read bw mask from: self.mask_paths[j]\n","            rgb, bw = random_image_and_mask(self.config)\n","\n","            # Run Augmentation\n","            if self.augmenter is not None:\n","                transformed = self.augmenter(image=rgb, mask=bw, keypoints=[])\n","                transformed_image = transformed['image']\n","                transformed_mask = transformed['mask']\n","            else:\n","                transformed_image = rgb\n","                transformed_mask = bw\n","\n","            if len(transformed_mask.shape) == 2:\n","                transformed_mask = transformed_mask[..., np.newaxis]\n","\n","            batch_x.append(transformed_image)\n","            batch_y.append(transformed_mask)\n","\n","        batch_x = np.array(batch_x)\n","        batch_y = np.array(batch_y)\n","\n","        # standardize\n","        batch_x = (batch_x.astype(np.float32) / 255) - 0.5\n","        batch_y = (batch_y > 127).astype(np.float32)\n","\n","        return batch_x, batch_y"],"metadata":{"id":"ybg0QWrINHcR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Train\n","\n","With all the functions declared and parameters set, we can train the CNN model on the dataset."],"metadata":{"id":"1b6IkduxNtg3"}},{"cell_type":"code","source":["# COLAB ONLY: Check for GPU environment\n","!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZRC2eicsOOrt","executionInfo":{"status":"ok","timestamp":1655386691437,"user_tz":240,"elapsed":8,"user":{"displayName":"Jaewoo Park","userId":"13416474115295697096"}},"outputId":"c7271eca-3171-4f4e-9f6c-016379cae3d5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n","\n"]}]},{"cell_type":"code","source":["import os\n","from datetime import datetime\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard\n","from keras import backend as K"],"metadata":{"id":"uA02caIFHoBd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Function to calculate the jaccard distance:\n","# https://opensourcebiology.eu/2021/09/22/how-to-understand-this-jaccard-distance/\n","def jaccard_distance(y_true, y_pred, smooth=100):\n","    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n","    sum_ = K.sum(K.abs(y_true) + K.abs(y_pred), axis=-1)\n","    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n","    return (1 - jac) * smooth"],"metadata":{"id":"FTPT9vMHHqVA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Set up datasets (currently dummy data)\n","x_train = [''] * 10000  # TODO: not used for this demo of random images... Later, set to file paths\n","y_train = [''] * 10000  # TODO: not used for this demo of random images... Later, set to file paths\n","x_val = [''] * 100  # TODO: not used for this demo of random images... Later, set to file paths\n","y_val = [''] * 100  # TODO: not used for this demo of random images... Later, set to file path"],"metadata":{"id":"LIrsyG27HtR3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["This dataset is made of emptty strings and it is only used to test the code's execution. When using real data, the varibles need to be set to a directory path, like:"],"metadata":{"id":"ZV7mSxkwHx99"}},{"cell_type":"code","source":["# Set up datasets (sample)\n","x_train = 'data/Training_Input'\n","y_train = 'data/Training_GroundTruth/pigment_network'\n","x_val = 'data/Validation_Input' \n","y_val = 'data/Validation_GroundTruth/pigment_network' "],"metadata":{"id":"gSgiWVUvIJdY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Used to apply data augmentation to the data\n","train_generator = IteratorWithAug(\n","    image_paths=x_train,\n","    mask_paths=y_train,\n","    config=config,\n","    augmenter= config.AUGMENTER_TRAIN,\n","    mode='train',\n","    shuffle=True,\n","    batch_size= config.BATCH_SIZE\n",")\n","\n","val_generator = IteratorWithAug(\n","    image_paths=x_val,\n","    mask_paths=y_val,\n","    config=config,\n","    augmenter= config.AUGMENTER_VAL,\n","    mode='val',\n","    shuffle=False,\n","    batch_size= config.BATCH_SIZE\n",")"],"metadata":{"id":"tAxuvECtIT3f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Set up log dir\n","datetime_str = datetime.now().strftime('%Y-%m-%d %H-%M-%S')\n","LOG_DIR = os.path.join(r'.\\logs', datetime_str)"],"metadata":{"id":"N_bulfP2IfHZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Build Model\n","net = Unet(outchns= config.CLASSES)\n","model = net.model\n","\n","# Compile model\n","model.compile(\n","    optimizer=Adam(learning_rate=0.1),\n","    loss='mean_squared_error',\n","    metrics=[\n","        jaccard_distance\n","    ]\n",")"],"metadata":{"id":"Z_s2rA1kIlZC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train\n","model.fit(\n","    train_generator,\n","    steps_per_epoch=len(train_generator),\n","    epochs= 25,\n","    validation_data=val_generator,\n","    validation_steps=len(val_generator),\n","    callbacks=[\n","        ModelCheckpoint(os.path.join(LOG_DIR, 'weights_{epoch:02d}.h5'), save_weights_only=False),\n","        TensorBoard(LOG_DIR, write_graph=False)\n","    ]\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":443},"id":"PJ3M-Dz1C7SF","executionInfo":{"status":"error","timestamp":1655386706520,"user_tz":240,"elapsed":14266,"user":{"displayName":"Jaewoo Park","userId":"13416474115295697096"}},"outputId":"f36b2fdc-c7ce-4424-8fec-a7de8c217bf1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/25\n","1/1 [==============================] - 8s 8s/step - loss: 0.3128 - jaccard_distance: 0.4950 - val_loss: 0.6983 - val_jaccard_distance: 0.6919\n","Epoch 2/25\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-152-fb0089eb70d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     callbacks=[\n\u001b[1;32m      9\u001b[0m         \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLOG_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'weights_{epoch:02d}.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_weights_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mTensorBoard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLOG_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     ]\n\u001b[1;32m     12\u001b[0m )\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["# Setup for using the actual data\n","\n","We use the following 2 cells to mount the colab with our drive.\n","Once mounted, set the path to be equal to where you have the data stored in your drive.\n","\n","Once the data is loaded, you can edit the x and y values above to be equal to the path where you have the training and testing datasets.\n"],"metadata":{"id":"kTjWXyst7Kyt"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"dC7FpYGqqFBA"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zGvhaid1ID3w"},"outputs":[],"source":["import os\n","os.getcwd()\n","path = '/content/drive/My Drive/CanField'\n","os.chdir(path)"]},{"cell_type":"markdown","source":["## Classify single image\n","\n","Once the model is trained on real data, we can use it to classify different images."],"metadata":{"id":"rCSCxd0XEDn7"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","import cv2"],"metadata":{"id":"bPmlM9_QF-HA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["img = mpimg.imread('data/Validation_Input/ISIC_0012585.jpg')\n","plt.imshow(img)\n","plt.show()"],"metadata":{"id":"GBZGaOteGMlp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2\n","img_array = cv2.imread('data/Validation_Input/ISIC_0012585.jpg')\n","new_array = cv2.resize(img_array, (160, 160))\n","final_img = new_array.reshape(-1, 160, 160, 3)\n","prediction = model.predict([final_img])\n","print(prediction)"],"metadata":{"id":"RP_S5XnZHR54"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["count_zeros = 0\n","for i in prediction:\n","  for j in i:\n","    if j[0] == 0:\n","      count_zeros += 1\n","  \n","print(count_zeros)"],"metadata":{"id":"yLc0OZyYZtjk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(prediction.shape)"],"metadata":{"id":"-bBeo6wgK6bB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from PIL import Image\n","\n","data = np.reshape(prediction, (160, 160))\n","img = Image.fromarray(data, '1')\n","img.save('test2.png')\n","img.show()"],"metadata":{"id":"01G8kpeBZhwv"},"execution_count":null,"outputs":[]}]}